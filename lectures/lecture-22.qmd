---
title: "Lecture 22: Digital Audio"
subtitle: "Part 1"
date: "4/18/2023"
order: 22
format: revealjs
---

## Daily Quiz

## Announcements

::: incremental
-   Group project
    -   Rough draft of your final report has been returned
        -   I uploaded commented versions of your files. You must make the changes that I noted in your final version.
    -   Final draft will be due Friday, April 21
        -   This includes an individual personal reflection that will be posted to Canvas.
    -   Final presentations will be **Friday, April 28 at 1:30pm**
-   Last Exam
    -   The last "midterm" exam will be **Tuesday, April 25**
    -   Same format as previous exams
    -   Topics: Architectural acoustics, analog and digital audio
:::

# Review: Analog sound transmission and reproduction

## Fidelity

*Fidelity* is a measure of how accurately the output sound matches the input sound. This is an objective measurement: we can define it using math.

Often the word "fidelity" is used colloquially to mean "subjectively sounds good." Much of the debate about the quality of recordings or amplifiers is really about personal preference, not mathematical accuracy.

Key aspects of fidelity are

-   minimal noise
-   flat frequency response
-   minimal distortion

## Analog sound chain

The sequence of events from the production of a sound to its reception by the listener is the *sound chain*.

![](figs/lecture-22/SoundChain-AnalogPlus.svg){style="scale:0.6;"}

Each step of the chain and each transition can reduce fidelity. Importantly, analog noise sources are *random* and *unpredictable*, and analog storage media *degrade over time*.

# Analog to digital conversion

## Analog and Digital

::: columns
::: {.column width="60%"}
An *analog* signal is something that changes smoothly over time and space. Mathematically, analog signals are represented by *functions* of *real numbers*. - A *digital* signal comes in countable pieces. Mathematically, digital signals are represented by *sequences* of *integers*.

Digital representations of analog signals are inherently approximations.
:::

::: {.column width="40%"}
![](figs/lecture-22/Digital.signal.discret.svg)

::: {style="font-size:80%"}
An analog signal (gray) and its approximation as a digital sequence (red).  The red dots can only be placed where the dashed lines cross.  This causes *digitization errors*.
:::
:::
:::

## Binary numbers

::: columns
::: {.column width="70%"}
*Binary* is a way of representing numbers based on powers of 2.
Each digit can be zero or one, and each place represents a power of 2.

::: fragment
For example, the number 42 is represented in binary by 101010

::: {style="text-align:center"}
| 32 | 16 | 8 | 4 | 2 | 1 |
|----|----|---|---|---|---|
| 1 | 0 | 1 | 0 | 1 | 0 |


32+8+2 = 42
:::
:::
:::

::: {.column width="30%"}
::: {style="font-size:80%"}
| Decimal | Binary |
|---------|--------|
| 0       | 0      |
| 1       | 1      |
| 2       | 10     |
| 3       | 11     |
| 4       | 100    |
| 5       | 101    |
| 6       | 110    |
| 7       | 111    |
| 8       | 1000   |
:::
:::
:::

## Bit depth

::: {.columns}
::: {.column width=60%}
The *bit depth* is the maximum number of binary digits (bits) that can be used to represent a number.
If the bit depth is *b*, then we can represent all numbers between zero and $2^b-1$.

::: fragment
If the incoming signal is bigger than the maximum value of the sampling bit depth, *clipping* occurs.  This is similar to saturation in analog amplifiers and causes harmonic distortion.
:::

::: fragment
To avoid clipping and saturation, audio engineers purposefully reduce the gain to allow *headroom* between the peak intensity of the signal and the maximum value at which clipping or saturation occurs.
:::

:::
::: {.column width=40%}
::: {style="font-size:80%"}
|Bit depth | Maximum value |
|----------|---------------|
| 1 | 1 |
| 2 | 3 |
| 3 | 7 |
| 4 | 15 | 
| 5 | 31 | 
| ... | ... |
| 8 | 255 |
| 12 | 4096 |
| 16 | 65535 |
| 24 | 16,777,215 |
:::
:::
:::

## Dynamic Range

::: {.columns}
::: {.column width=60%}
There is a direct connection between bit depth and dynamic range.
*Dynamic range* is the ratio between the largest and smallest signal allowed.

::: fragment
The two are related by

$$
\mathrm{DNR} = (20 \mathrm{dB}) \log (2^b) \approx b \times (6\,\mathrm{dB})
$$

:::
::: fragment
For example, the dynamic range of human hearing is about 140 dB (from threshold of hearing to pain).  To cover this whole range requires a bit depth of about $b = \frac{140 \mathrm{dB}}{6 \mathrm{dB}} = 23\,\text{bits}$.  Studio audio is often at 24 bits for this reason.
:::
:::
::: {.column width=40%}
::: {style="font-size:80%"}
![](figs/lecture-22/2-Dynamic-Range.jpg)

::: { style="font-size:60%"}
Figure: <http://urm.academy>
:::

:::
:::
:::

## Digitizing Waveforms

::: columns
::: {.column width="60%"}
Converting an analog signal (e.g. voltage varying over time) to digital requires chopping the signal up in both time and amplitude. Usually the spacing on both time and amplitude is even.

This conversion process is called *sampling*.

-   The *time step* (*T*) is the time between samples.
-   The *sampling rate* (*f~s~*) is the number of time steps in one second (e.g. 40000 samples per second). $f_s=1/T$
-   The *bit depth* (*b*) gives the number of steps in amplitude

:::

::: {.column width="40%"}
![](figs/lecture-22/Conversion_AD_DA.png)
:::
:::

## Digitization errors

Digitization error is a loss in fidelity caused by the digitization process.

- *Sampling errors* are errors in time. For example: uneven time steps or too-low sampling rate
- *Quantization errors* are errors in amplitude. For example: low bit-depth or uneven amplitude steps

::: fragment
The bad reputation of digital audio among audiophiles is likely because early equipment (up through the 1970s) was susceptible to these types of errors.  Modern digital hardware (even cheap hardware) has much greater fidelity than the comparable analog gear.
:::

::: fragment
Also, because digital signals can be easily processed in *software*, many types of digitization errors can be cleaned up in post-processing if higher bit-depth and sampling rates are used.
The computer power to do this wasn't available in the early days of digital audio.
:::

## Sampling Rates and the Nyquist frequency

::: {.columns}
::: {.column width=60% }
To faithfully represent an analog signal containing frequencies up to some *f*~max~, the data must be sample rate must be at least twice *f*~max~.  This is the "[Nyquist-Shannon Sampling Theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem)".  The *Nyquist frequency* *f~N~* is simply

$$
f_N = 2f_\text{max}.
$$

Sampling at a rate less than *f~N~* is called *undersampling* and causes a type of distortion called *aliasing*, introducing false frequencies into the signal.

Sampling at a rate greater than *f~N~* is called *oversampling*.  This doesn't give any additional fidelity, but is often done to provide a buffer for later digital processing.
:::
::: {.column width=40%}
![Two signals sampled at 8 kHz. [Source](https://xiengineering.com/sampling-frequency-audio-aliasing/)](figs/lecture-22/1khz-and-7khz.png){ width=100%} 
:::
:::

## Sampling rate examples

For example, the sampling rate of CD-quality audio is [44,100 Hz](https://en.wikipedia.org/wiki/44,100_Hz), roughly twice the maximum frequency that humans can hear.  The exact number was chosen by Sony because it is easily subdivided: 44,100 = (2&times;3&times;5&times;7)^2^.

Large sampling rates and bit depths provide the best fidelity but at the cost of large file sizes or large streaming bandwidth requirements.  This is good in the studio, but for distribution the final product needs to be smaller.

## Video: Bit depth and sample rate

<iframe width="1120" height="630" src="https://www.youtube.com/embed/O3xD_5bwzaE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Data Compression
::: {.columns}
::: {.column width=60%}

The first step is to reduce the bit depth and sampling rate to something commensurate with consumer audio equipment.  For example, the CD standard is 44,100 Hz and 16 bits.

To further reduce the file size *compression* is used.  This is a mathematical process to eliminate redundant information from the file.  There are two types:

- *Lossless* compression uses math theorems to reduce the file size while being able to restore the original data exactly
- *Lossy* compression uses math plus a model of human hearing to discard additional information while minimally affecting the perception of the sound.

(This is different from *dynamic compression*, which adjusts amplitudes to even out volume.)

:::
::: {.column width=40%}
::: {style="font-size:80%"}
Uncompressed file types:

- WAV, PCM

Lossless file types:

- FLAC, ATRAC, ALAC

Lossy file types:

- MP3, OGG, AAC

:::
:::
::::

## Lossy vs. Lossless

<iframe width="1120" height="630" src="https://www.youtube.com/embed/eN49E0cRGME" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>